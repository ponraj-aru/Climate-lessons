{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excerise 3: Downscaling near-future predictions of climatic variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor,GradientBoostingClassifier\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel(\"C:\\\\Users\\\\arumu002\\\\OneDrive - Wageningen University & Research\\\\Project I\\\\Rutger\\\\statitical downscaling\\\\\\Station_data_NL_1987_2023.xlsx\")\n",
    "df1 = train_df.dropna()\n",
    "values_to_drop = [2021,2022,2023]\n",
    "df = df1[~df1['YEAR'].isin(values_to_drop)]\n",
    "df2 = df1[df1['YEAR'].isin(values_to_drop)]\n",
    "\n",
    "#data_X = df.drop([\"Year\",\"Yield\"],axis=1)\n",
    "data_X = df.drop([\"tmax\",\"tmin\",\"tas\"],axis=1)\n",
    "data_y = df['tmax']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2)\n",
    "\n",
    "#X_test1 = df2.drop([\"Year\",\"Yield\"],axis=1)\n",
    "X_test1 = df2.drop([\"tmax\",\"tmin\",\"tas\"],axis=1)\n",
    "y_test1 = df2['tmax']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Develop ML model to validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "                                learning_rate=0.2, loss='squared_error', max_depth=8,\n",
    "                                max_features='sqrt', max_leaf_nodes=None,\n",
    "                                min_impurity_decrease=0.0,\n",
    "                                min_samples_leaf=100, min_samples_split=1000,\n",
    "                                min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
    "                                n_iter_no_change=None,\n",
    "                                random_state=10, subsample=1, tol=0.0001,\n",
    "                                validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "new.fit(X_train, y_train)\n",
    "y_pred = new.predict(X_test1)\n",
    "mse = mean_squared_error(y_test1, y_pred)\n",
    "print(f'The mean squared error (MSE) on test set: {mse:.4f}')\n",
    "r2_scores = cross_val_score(new, X_train, y_train, cv=3, scoring='r2')\n",
    "k_fold = r2_scores.mean()\n",
    "print(f'The k-fold validation (R2) on test set: {k_fold:.4f}')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(y_test1, y_pred)\n",
    "r_squared = r_value**2\n",
    "print(f'The  validation (R2) on test set: {r_squared:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "#plt.plot(X, y, c='k', label='data')\n",
    "# Create a scatter plot\n",
    "axs[0].scatter(y_test1, y_pred)\n",
    "# Add a 1:1 line\n",
    "axs[0].plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)], linestyle='--', color='gray', label='1:1 line')\n",
    "# Perform linear regression to calculate R2\n",
    "slope, intercept, r_value, p_value, std_err = linregress(y_test1, y_pred)\n",
    "r_squared = r_value**2\n",
    "# Add labels and a title\n",
    "axs[0].set_xlabel('Observed')\n",
    "axs[0].set_ylabel('Predicted')\n",
    "axs[0].set_title('Observed Vs Predicted')\n",
    "axs[0].annotate(f'R2 = {r_squared:.2f}', xy=(0.1, 0.85), xycoords='axes fraction', fontsize=18)\n",
    "axs[0].annotate(f'MSE = {mse:.2f}', xy=(0.1, 0.75), xycoords='axes fraction', fontsize=18)\n",
    "# Show the plot\n",
    "\n",
    "feature_importance = new.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "top_n = 10\n",
    "top_feature_indices = sorted_idx[-top_n:]\n",
    "top_feature_importance = feature_importance[top_feature_indices]\n",
    "top_feature_names = np.array(X_train.columns)[top_feature_indices]\n",
    "# Create the plot\n",
    "axs[1].barh(pos[-top_n:], top_feature_importance, align=\"center\")\n",
    "axs[1].set_yticks(pos[-top_n:], top_feature_names)\n",
    "axs[1].set_title(\"Top 10 Feature Importance\")\n",
    "axs[1].set_xlabel(\"Importance\")\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
